{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for doc in Path('../data/documents').iterdir():\n",
    "    if doc.suffix != '.txt':\n",
    "        continue\n",
    "\n",
    "    with open(doc) as f:\n",
    "        data[doc.stem] = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class TextProcessor(ABC):\n",
    "    @abstractmethod\n",
    "    def transform(self, text):\n",
    "        pass\n",
    "\n",
    "    # transformer 1:\n",
    "\n",
    "class ConvertCase(TextProcessor):\n",
    "    def __init__(self, casing='lower'):\n",
    "        self.casing = casing\n",
    "\n",
    "    def transform(self, text):\n",
    "        if self.casing == 'lower':\n",
    "            return text.lower()\n",
    "        elif self.casing == 'upper':\n",
    "            return text.upper()\n",
    "        elif self.casing == 'title':\n",
    "            return text.title()\n",
    "\n",
    "\n",
    "# transformer 2:\n",
    "\n",
    "class RemoveDigit(TextProcessor):\n",
    "    def transform(self, text):\n",
    "        text = ''.join(filter(lambda char: not char.isdigit(), text))\n",
    "        return text\n",
    "\n",
    "\n",
    "# transformer 3:\n",
    "\n",
    "class RemoveSpace(TextProcessor):\n",
    "    def transform(self, text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "\n",
    "# transformer 4:\n",
    "\n",
    "class RemovePunkt(TextProcessor):\n",
    "    def __init__(self, replace_char=' '):\n",
    "        self.replace_char = replace_char\n",
    "\n",
    "    def transform(self, text):\n",
    "        return ''.join(char if char not in punctuation else self.replace_char for char in text)\n",
    "\n",
    "\n",
    "# pipeline:\n",
    "\n",
    "class StringPipeline:\n",
    "    def __init__(self, *args):\n",
    "        self.transformers = args\n",
    "\n",
    "    def transform(self, text):\n",
    "        for i in self.transformers:\n",
    "            text = i.transform(text)\n",
    "        return text\n",
    "\n",
    "    def __str__(self):\n",
    "        return '''Transforms text with transformers:\n",
    "        ConvertCase(lower,upper,title) RemoveDigit RemovePunkt RemoveSpace'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = StringPipeline(\n",
    "        ConvertCase('lower'),\n",
    "        RemoveSpace(),\n",
    "        RemovePunkt(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = open('../data/stop_words.txt').readlines()\n",
    "stop_words = list(map(str.strip, stop_words))\n",
    "stop_words = set(map(pipeline.transform, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing = {}\n",
    "for doc_name, doc_content in data.items():\n",
    "\n",
    "    words = pipeline.transform(doc_content).split()\n",
    "\n",
    "    for i in words:\n",
    "        if i in stop_words:\n",
    "            continue\n",
    "        elif i not in indexing:\n",
    "            indexing[i] = {doc_name}\n",
    "        else:\n",
    "            indexing[i].add(doc_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m - adam sandler\u001b[0m\n",
      "\u001b[94m - michael jackson\u001b[0m\n",
      "\u001b[94m - jennifer lopez\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    search_input = input('search here or \"q\" to quit')\n",
    "    search_input = pipeline.transform(search_input)\n",
    "    if search_input == 'q':\n",
    "        break\n",
    "\n",
    "    search_tokens = search_input.split()\n",
    "    result = []\n",
    "    for token in search_tokens:\n",
    "        result.extend(indexing.get(token, []))\n",
    "\n",
    "    from termcolor import colored\n",
    "\n",
    "    for i in result:\n",
    "        print(colored(f' - {i}','light_blue'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
